{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/movielens-20m-dataset/rating.csv\n",
      "/kaggle/input/movielens-20m-dataset/movie.csv\n",
      "/kaggle/input/movielens-20m-dataset/link.csv\n",
      "/kaggle/input/movielens-20m-dataset/genome_tags.csv\n",
      "/kaggle/input/movielens-20m-dataset/tag.csv\n",
      "/kaggle/input/movielens-20m-dataset/genome_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\r\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 39kB/s \r\n",
      "\u001b[?25hCollecting py4j==0.10.7\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\r\n",
      "\u001b[K     |████████████████████████████████| 204kB 40.5MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216131250 sha256=43f796cf3d9612b2d593c4621a4a58d44c30b1e31d7bb563604debbc494d7548\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.sql(\"select 'spark' as hello\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = spark.read.csv(\"../input/movielens/ratings.csv\", inferSchema=True, header=True)\n",
    "movie_ratings = movie_ratings.select('userId', 'movieId', 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movie_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      2|   3.5|\n",
      "|     1|     29|   3.5|\n",
      "|     1|     32|   3.5|\n",
      "|     1|     47|   3.5|\n",
      "|     1|     50|   3.5|\n",
      "|     1|    112|   3.5|\n",
      "|     1|    151|   4.0|\n",
      "|     1|    223|   4.0|\n",
      "|     1|    253|   4.0|\n",
      "|     1|    260|   4.0|\n",
      "|     1|    293|   4.0|\n",
      "|     1|    296|   4.0|\n",
      "|     1|    318|   4.0|\n",
      "|     1|    337|   3.5|\n",
      "|     1|    367|   3.5|\n",
      "|     1|    541|   4.0|\n",
      "|     1|    589|   3.5|\n",
      "|     1|    593|   3.5|\n",
      "|     1|    653|   3.0|\n",
      "|     1|    919|   3.5|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movie_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegressionEvaluator pour évaluer la performance du modèle ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Alternating Least Squares (Alternance des moindres carrés)\n",
    "from pyspark.ml.recommendation import ALS\n",
    "# CrossValidator pour diviser la dataset en training and testing\n",
    "# ParamGridBuilder pour affiner les paramètres de notre modèle\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de training set et test set\n",
    "(training, test) = movie_ratings.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle ALS (Alternating Least Saqures)\n",
    "als = ALS(userCol='userId', itemCol='movieId', ratingCol='rating', coldStartStrategy='drop', nonnegative=True)\n",
    "\n",
    "# nonnegative=True : car on veut pas qu'il nous retourne des valeurs négatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Régler le modèle en utilisant ParamGridBuilder\n",
    "param_grid = ParamGridBuilder().addGrid(als.rank, [12, 13, 14]).addGrid(als.maxIter, [18, 19, 20]).addGrid(als.regParam, [.17, .18, .19]).build()\n",
    "\n",
    "# On le donne :\n",
    "# les paramètres des matrices U et P\n",
    "# max iterations qui disent à Spark combien de fois alterner entre U et P pour minimiser l'erreur\n",
    "# le paramètre de régularisation pour empêcher ALS de sur-adapter aux données (overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir l'Évaluateur de régression, qui attend la prédiction des colonnes d'entrée\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "\n",
    "# predictionCol='prediction' : le nom de la colonne des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction de cross validation\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# estimator=als : pour utiliser le modèle de ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modèle avec les données d'entraînement\n",
    "model = cv.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le meilleur modèle de l'exercice de tournage à l'aide de ParamGridBuilder\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer des prédictions et évaluer à l'aide de RMSE\n",
    "predictions = best_model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "# rmse : Écart quadratique moyen (Root-mean-square deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.8517008116870236\n",
      "**Best model**\n",
      "Rank : \n",
      "MaxIter : \n",
      "RegParam : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les métriques d'évaluation et les paramètres du modèle\n",
    "print(\"RMSE = \" + str(rmse))\n",
    "print(\"**Best model**\")\n",
    "print(\"Rank : \"), best_model.rank\n",
    "print(\"MaxIter : \"), best_model._java_obj.parent().getMaxIter()\n",
    "print(\"RegParam : \"), best_model._java_obj.parent().getRegParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: bigint, movieId: bigint, rating: double, prediction: float]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparer les prédictions des évaluations des utilisateurs (ratings) avec les évaluations réels\n",
    "display(predictions.sort('userId', 'rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|   3932|   3.0|  3.321066|\n",
      "|     1|    653|   3.0| 3.2634063|\n",
      "|     1|   1525|   3.0| 2.6832097|\n",
      "|     1|   2194|   3.5|   3.76578|\n",
      "|     1|   3476|   3.5| 3.3637607|\n",
      "|     1|   6807|   3.5| 3.6391315|\n",
      "|     1|   6242|   3.5|  3.511706|\n",
      "|     1|   4941|   3.5|  2.985636|\n",
      "|     1|   7247|   3.5| 3.2979224|\n",
      "|     1|   5679|   3.5| 3.3537078|\n",
      "|     1|   2253|   3.5|   2.69537|\n",
      "|     1|   3438|   3.5| 2.8893774|\n",
      "|     1|   3997|   3.5| 1.9998069|\n",
      "|     1|   1193|   3.5| 3.9263577|\n",
      "|     1|   8482|   3.5| 3.7055633|\n",
      "|     1|   7449|   3.5| 2.3705983|\n",
      "|     1|   4720|   3.5| 3.6240416|\n",
      "|     1|   4105|   3.5|  3.617806|\n",
      "|     1|   7164|   3.5|  3.373713|\n",
      "|     1|   6774|   4.0|  3.357091|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.sort('userId', 'rating').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génerer les prédiction des évaluations de tous les utilisateurs\n",
    "users_recommendations = best_model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|  1580|[[59295, 3.488422...|\n",
      "|  4900|[[6600, 6.262145]...|\n",
      "|  5300|[[6600, 6.682314]...|\n",
      "|  6620|[[6600, 6.130567]...|\n",
      "|   471|[[6600, 5.480845]...|\n",
      "|  1591|[[6600, 6.2523136...|\n",
      "|  4101|[[6600, 5.723655]...|\n",
      "|  1342|[[6600, 6.363829]...|\n",
      "|  2122|[[63194, 4.738602...|\n",
      "|  2142|[[6600, 5.79335],...|\n",
      "|   463|[[6600, 6.1415944...|\n",
      "|   833|[[6600, 6.0323668...|\n",
      "|  5803|[[6600, 7.128424]...|\n",
      "|  3794|[[6600, 6.0814853...|\n",
      "|  6654|[[6600, 6.888523]...|\n",
      "|  1645|[[6600, 5.8292694...|\n",
      "|  3175|[[6600, 6.988644]...|\n",
      "|  4935|[[6600, 5.3088], ...|\n",
      "|   496|[[6600, 6.589501]...|\n",
      "|  2366|[[6600, 6.3854437...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLContext : Le point d'entrée pour travailler avec des données structurées (lignes et colonnes) dans Spark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour faciliter l'affichage de users_recommendations\n",
    "\n",
    "def get_recs_for_user(recs):\n",
    "    recs = recs.select(\"userId\", \"recommendations.movieId\", \"recommendations.rating\")\n",
    "    movies = recs.select(\"movieId\").toPandas().iloc[:, 0].values\n",
    "    ratings = recs.select(\"rating\").toPandas().iloc[:, 0].values\n",
    "    userIds = recs.select(\"userId\").toPandas()\n",
    "    ratings_matrix = pd.DataFrame(movies, columns=['movieId'])\n",
    "    #ratings_matrix['userId'] = userIds\n",
    "    ratings_matrix.insert(0, 'userId', userIds)\n",
    "    ratings_matrix['ratings'] = ratings\n",
    "    ratings_matrix_ps = sqlContext.createDataFrame(ratings_matrix)\n",
    "    return ratings_matrix_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_recs = get_recs_for_user(users_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|userId|             movieId|             ratings|\n",
      "+------+--------------------+--------------------+\n",
      "|  1580|[59295, 69685, 94...|[3.48842239379882...|\n",
      "|  4900|[6600, 95776, 829...|[6.26214504241943...|\n",
      "|  5300|[6600, 82931, 957...|[6.68231391906738...|\n",
      "|  6620|[6600, 727, 82931...|[6.13056707382202...|\n",
      "|   471|[6600, 95776, 829...|[5.48084497451782...|\n",
      "|  1591|[6600, 727, 82931...|[6.25231361389160...|\n",
      "|  4101|[6600, 82931, 957...|[5.72365522384643...|\n",
      "|  1342|[6600, 82931, 727...|[6.36382913589477...|\n",
      "|  2122|[63194, 6160, 109...|[4.73860263824462...|\n",
      "|  2142|[6600, 26325, 470...|[5.79335021972656...|\n",
      "|   463|[6600, 727, 82931...|[6.14159440994262...|\n",
      "|   833|[6600, 95776, 514...|[6.03236675262451...|\n",
      "|  5803|[6600, 95776, 829...|[7.12842416763305...|\n",
      "|  3794|[6600, 95776, 829...|[6.08148527145385...|\n",
      "|  6654|[6600, 95776, 223...|[6.88852310180664...|\n",
      "|  1645|[6600, 727, 82931...|[5.82926940917968...|\n",
      "|  3175|[6600, 95776, 829...|[6.98864412307739...|\n",
      "|  4935|[6600, 82931, 957...|[5.30880022048950...|\n",
      "|   496|[6600, 82931, 957...|[6.58950090408325...|\n",
      "|  2366|[6600, 95776, 829...|[6.38544368743896...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDF = spark.read.csv(\"../input/movielens/movies.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user10 = pd.DataFrame({\"userCol\": 10})\n",
    "#user10_recommendations = best_model.recommendForUserSubset(user10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire de users_recommendations les recommandations pour un utilisateur spécifique\n",
    "\n",
    "user_recs = users_recs.filter(\"userId=10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|userId|             movieId|             ratings|\n",
      "+------+--------------------+--------------------+\n",
      "|    10|[6600, 82931, 957...|[5.69969797134399...|\n",
      "+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour changer l'affichage de la liste des ids des films\n",
    "\n",
    "z = []\n",
    "\n",
    "for k,row in user_recs.toPandas().iterrows():\n",
    "    for j in list(np.array(row.movieId).flat):\n",
    "        z.append({'userId':row.userId, 'movieId':j})\n",
    "\n",
    "user_recs = spark.createDataFrame(pd.DataFrame(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joindre la dataframe des films recommandés pour l'utilisateur avec leurs titres et genres\n",
    "\n",
    "user_recs = user_recs.join(movieDF, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour échanger les indexs de 'userId' et 'movieId'\n",
    "\n",
    "user_recs = user_recs['userId', 'movieId', 'title', 'genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+--------------------+\n",
      "|userId|movieId|               title|              genres|\n",
      "+------+-------+--------------------+--------------------+\n",
      "|    10|   6600|...And God Spoke ...|              Comedy|\n",
      "|    10|  82931|Last Circus, The ...|    Comedy|Drama|War|\n",
      "|    10|  95776|     Bob Funk (2009)|      Comedy|Romance|\n",
      "|    10|    727|  War Stories (1995)|         Documentary|\n",
      "|    10|   4261|       Lilies (1996)|Drama|Fantasy|Rom...|\n",
      "|    10|  88570|      Welfare (1975)|         Documentary|\n",
      "|    10| 100902|911 in Plane Site...|         Documentary|\n",
      "|    10| 100106|Pervert's Guide t...|         Documentary|\n",
      "|    10|   7113|Cabeza de Vaca (1...|    Action|Adventure|\n",
      "|    10|  47028|Sione's Wedding (...|      Comedy|Romance|\n",
      "+------+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
